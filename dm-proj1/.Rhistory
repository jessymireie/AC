library(tidyverse)
install.packages("tidyverse")
install.packages("devtools")
library(tidyverse)
library(tidyverse)
devtools::install_github("tidyverse/tidyverse")
library(ggplot2)
packages.install('tidyverse')
install.packages("tidyverse")
install.packages("readr", dependencies=TRUE, INSTALL_opts = c('--no-lock'))
install.packages("readr", dependencies=TRUE, INSTALL_opts = c('--no-lock'))
library(tidyverse)
#library(psych)
library(dplyr)
library(readr)
clients <- read.csv('ficheiros_competicao/client.csv',sep = ';', header=TRUE)
setwd("~/Documents/AC/dm-proj1")
# XGBoost
# install.packages("xgboost")
library(xgboost)
library(caret)
# Load dataset
train <- read.csv('final_train.csv',sep = ',', header=TRUE)
test <- read.csv('final_test.csv',sep = ',', header=TRUE)
# Converting 'status' to a factor
train$status <- factor(train$status)
# Set a random seed
set.seed(51)
model <- train(status ~ payments_loan + duration_loan + num_credit + avg_credit + max_credit + min_credit + median_credit + iqr_credit
+ num_withdrawal + avg_withdrawal + max_withdrawal + min_withdrawal + median_withdrawal + iqr_withdrawal
+ avg_amount + median_amount + iqr_amount + max_balance + min_balance + avg_balance + median_balance + iqr_balance + frequency_num
+ avg_monthly_balance + time_bf_loan + age_at_loan + card_num,
data = train,
method = 'xgbTree',
trControl = trainControl(method = 'cv', number = 5,verbose = TRUE, allowParallel = TRUE))
#Score the test population (predict values in test set)
test$status <- predict(model, newdata = test, type='prob')
results <- test[,c("loan_id","status")]
results$status_neg_prob <- results$status$`-1`
export <- results[,c("loan_id", "status_neg_prob")]
names(export)[names(export) == 'loan_id' ] <- 'Id'
names(export)[names(export) == 'status_neg_prob' ] <- 'Predicted'
write.csv(export,"xgb_first.csv", row.names = FALSE)
##### GETTING MODEL ACCURACY
# define an 80%/20% train/test split of the dataset
split=0.80
trainIndex <- createDataPartition(train$status, p=split, list=FALSE)
data_train <- train[ trainIndex,]
data_test <- train[-trainIndex,]
# train a model
model <- train(status ~ payments_loan + duration_loan + num_credit + avg_credit + max_credit + min_credit + median_credit + iqr_credit
+ num_withdrawal + avg_withdrawal + max_withdrawal + min_withdrawal + median_withdrawal + iqr_withdrawal
+ avg_amount + median_amount + iqr_amount + max_balance + min_balance + avg_balance + median_balance + iqr_balance + frequency_num
+ avg_monthly_balance + time_bf_loan + age_at_loan + card_num,
data = data_train,
method = 'xgbTree',
trControl =  trainControl(method = 'cv', number = 5,verbose = TRUE, allowParallel = TRUE))
# make predictions
x_test <- subset(data_test, select = -status )
y_test <- data_test$status
predictions <- predict(model, x_test)
# summarize results
confusionMatrix(predictions, y_test)
library(caret)
library(randomForest)
install.packages("randomForest")
library(randomForest)
library(randomForest)
library(caret)
library(randomForest)
install.packages("randomForest")
library(caret)
library(randomForest)
