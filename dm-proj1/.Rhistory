print(boruta_signif)
features <- append(boruta_signif, "status")
filtered_train <- train[,features]
rm(boruta_output)
rm(boruta_signif)
rm(features)
model2 <- train(status~., data = filtered_train, method = 'glm', metric="ROC", trControl = control, family= binomial)
print(model2)
grid <- expand.grid(parameter=c(0.001, 0.01, 0.1, 1,10,100, 1000))
model3 <- train(status~., data = train, method = 'glm', metric="ROC", tuneGrid = grid,  trControl = control, family= binomial)
print(model3)
model3$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
model4 <- train(status~., data = filtered_train, method = 'glm', metric="ROC", tuneGrid = grid,  trControl = control, family= binomial)
print(model4)
model4$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
library(caret)
library(mlbench)
library(gbm)
# Loading and Preparing Datasets
train <- read.csv('complete_train.csv',sep = ',', header=TRUE)
test <- read.csv('complete_test.csv',sep = ',', header=TRUE)
# Converting 'status' to a factor
train$status <- factor(train$status)
levels(train$status) <- c("Failed", "Succeeded")
train %>% relocate(status, .after = last_col())
train <- train %>%
mutate(card_num = case_when(
card_num == 'none' ~ 0,
card_num == 'classic' ~ 1,
card_num == 'junior' ~ 2,
card_num == 'gold' ~ 3))
test <- test %>%
mutate(card_num = case_when(
card_num == 'none' ~ 0,
card_num == 'classic' ~ 1,
card_num == 'junior' ~ 2,
card_num == 'gold' ~ 3))
train <- train %>%
mutate(frequency_num = case_when(
frequency_num == 'monthly issuance' ~ 0,
frequency_num == 'weekly issuance' ~ 1,
frequency_num == 'issuance after transaction' ~ 2))
test <- test %>%
mutate(frequency_num = case_when(
frequency_num == 'monthly issuance' ~ 0,
frequency_num == 'weekly issuance' ~ 1,
frequency_num == 'issuance after transaction' ~ 2))
train <- train %>%
mutate(gender = case_when(
gender == 'F' ~ 0,
gender == 'M' ~ 2))
test <- test %>%
mutate(gender = case_when(
gender == 'F' ~ 0,
gender == 'M' ~ 2))
# Set a random seed
set.seed(100)
# Control
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
library(Boruta)
boruta_output <- Boruta(status ~ ., data=na.omit(train), doTrace=0)
names(boruta_output)
# Get significant variables including tentatives
boruta_signif <- getSelectedAttributes(boruta_output, withTentative = TRUE)
print(boruta_signif)
features <- append(boruta_signif, "status")
filtered_train <- train[,features]
1/50
1/100
1/150
1/140
1/200
gbmGrid_t <-  expand.grid(interaction.depth = seq(1, 25, length = 25),
n.trees = seq(50, 500, length = 10),
shrinkage = seq(0, 1, length = 200),
n.minobsinnode = seq(10, 50, length = 5))
modelt <- train(status~., data = filtered_train, method = 'gbm', metric="ROC", trControl = control, tuneGrid = gbmGrid_t)
# top 5 results
modelt$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
print(modelt)
0.5/100
0.5/50
0.1/50
0.1/20
gbmGrid_t <-  expand.grid(interaction.depth = seq(5, 20, length = 15),
n.trees = seq(50, 500, length = 10),
shrinkage = seq(0, 0.1, length = 20),
n.minobsinnode = seq(10, 50, length = 5))
modelt <- train(status~., data = filtered_train, method = 'gbm', metric="ROC", trControl = control, tuneGrid = gbmGrid_t)
gbmGrid_t <-  expand.grid(interaction.depth = c(5, 7, 9, 11, 13, 15),
n.trees = c(50, 100, 150, 200, 250, 300),
shrinkage = c(0.015, 0.025, 0.035, 0.045),
n.minobsinnode = c(10, 20, 30, 40, 50))
modelt <- train(status~., data = filtered_train, method = 'gbm', metric="ROC", trControl = control, tuneGrid = gbmGrid_t)
# top 5 results
modelt$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
# Predicting
test$status <- predict(modelt, newdata = test, type = "prob")
# Save Results
results_2 <- test[,c("loan_id","status")]
results_2$status_neg_prob <- results_2$status$Failed
export <- results_2[,c("loan_id", "status_neg_prob")]
names(export)[names(export) == 'loan_id' ] <- 'Id'
names(export)[names(export) == 'status_neg_prob' ] <- 'Predicted'
rm(results_2)
write.csv(export,"results/gbm_grid_boruta_2.csv", row.names = FALSE)
rm(export)
test$status <- NULL
library(caret)
library(plyr)
library(xgboost)
# Loading and Preparing Datasets
train <- read.csv('complete_train.csv',sep = ',', header=TRUE)
test <- read.csv('complete_test.csv',sep = ',', header=TRUE)
# Converting 'status' to a factor
train$status <- factor(train$status)
levels(train$status) <- c("Failed", "Succeeded")
train %>% relocate(status, .after = last_col())
train <- train %>%
mutate(card_num = case_when(
card_num == 'none' ~ 0,
card_num == 'classic' ~ 1,
card_num == 'junior' ~ 2,
card_num == 'gold' ~ 3))
test <- test %>%
mutate(card_num = case_when(
card_num == 'none' ~ 0,
card_num == 'classic' ~ 1,
card_num == 'junior' ~ 2,
card_num == 'gold' ~ 3))
train <- train %>%
mutate(frequency_num = case_when(
frequency_num == 'monthly issuance' ~ 0,
frequency_num == 'weekly issuance' ~ 1,
frequency_num == 'issuance after transaction' ~ 2))
test <- test %>%
mutate(frequency_num = case_when(
frequency_num == 'monthly issuance' ~ 0,
frequency_num == 'weekly issuance' ~ 1,
frequency_num == 'issuance after transaction' ~ 2))
train <- train %>%
mutate(gender = case_when(
gender == 'F' ~ 0,
gender == 'M' ~ 2))
test <- test %>%
mutate(gender = case_when(
gender == 'F' ~ 0,
gender == 'M' ~ 2))
# Set a random seed
set.seed(100)
# Control
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
## 1 nothing
model <- train(status~., data = train, method = 'xgbDART', metric="ROC", trControl = control)
print(model)
library(caret)
library(xgboost)
# Loading and Preparing Datasets
train <- read.csv('complete_train.csv',sep = ',', header=TRUE)
test <- read.csv('complete_test.csv',sep = ',', header=TRUE)
# Converting 'status' to a factor
train$status <- factor(train$status)
levels(train$status) <- c("Failed", "Succeeded")
train %>% relocate(status, .after = last_col())
train <- train %>%
mutate(card_num = case_when(
card_num == 'none' ~ 0,
card_num == 'classic' ~ 1,
card_num == 'junior' ~ 2,
card_num == 'gold' ~ 3))
test <- test %>%
mutate(card_num = case_when(
card_num == 'none' ~ 0,
card_num == 'classic' ~ 1,
card_num == 'junior' ~ 2,
card_num == 'gold' ~ 3))
train <- train %>%
mutate(frequency_num = case_when(
frequency_num == 'monthly issuance' ~ 0,
frequency_num == 'weekly issuance' ~ 1,
frequency_num == 'issuance after transaction' ~ 2))
test <- test %>%
mutate(frequency_num = case_when(
frequency_num == 'monthly issuance' ~ 0,
frequency_num == 'weekly issuance' ~ 1,
frequency_num == 'issuance after transaction' ~ 2))
train <- train %>%
mutate(gender = case_when(
gender == 'F' ~ 0,
gender == 'M' ~ 2))
test <- test %>%
mutate(gender = case_when(
gender == 'F' ~ 0,
gender == 'M' ~ 2))
# Set a random seed
set.seed(100)
# Control
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
## 1 nothing
model <- train(status~., data = train, method = 'xgbLinear', metric="ROC", trControl = control)
print(model)
#interaction.depth  n.trees  ROC        Sens       Spec
#
# top 5 results
model$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
grid <-  expand.grid(
nrounds = c(100, 150, 200, 250, 300, 350),
eta = c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5),
lambda = c(2, 4, 6, 8, 10),
alpha = 0
)
model2 <- train(status~., data = train, method = 'xgbLinear', tuneGrid = grid, metric="ROC", trControl = control)
# top 5 results
model2$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
library(Boruta)
boruta_output <- Boruta(status ~ ., data=na.omit(train), doTrace=0)
names(boruta_output)
# Get significant variables including tentatives
boruta_signif <- getSelectedAttributes(boruta_output, withTentative = TRUE)
print(boruta_signif)
features <- append(boruta_signif, "status")
filtered_train <- train[,features]
model3 <- train(status~., data = filtered_train, method = 'xgbLinear', metric="ROC", trControl = control)
# top 5 results
model3$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
grid <-  expand.grid(
nrounds = c(100, 150, 200, 250, 300, 350),
eta = c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5),
max_depth = c(2, 4, 6, 8, 10),
gamma = 0,
colsample_bytree = 0.6,
min_child_weight = 1,
subsample = 0.5,
rate_drop = 0.5, skip_drop = 0.5
)
model4 <- train(status~., data = filtered_train, method = 'xgbLinear', tuneGrid = grid, metric="ROC", trControl = control)
# top 5 results
model4$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
#print(model4)
grid <-  expand.grid(
nrounds = c(100, 150, 200, 250, 300, 350),
eta = c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5),
lambda = c(2, 4, 6, 8, 10),
alpha = 0
)
model4 <- train(status~., data = filtered_train, method = 'xgbLinear', tuneGrid = grid, metric="ROC", trControl = control)
# top 5 results
model4$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
control_fs <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
train %>% relocate(status, .after = last_col())
results_fs <- rfe(train[,1:39], train[,40], sizes=c(1:39), rfeControl=control_fs)
# summarize the results
print(results_fs)
# list the chosen features
predictors(results_fs)
features <- append(predictors(results_fs), "status")
filtered_train_rfe <- train[,features]
model5 <- train(status~., data = filtered_train_rfe, method = 'xgbLinear', metric="ROC", trControl = control)
# top 5 results
model5$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
model6 <- train(status~., data = filtered_train, method = 'xgbLinear', tuneGrid = grid, metric="ROC", trControl = control)
# top 5 results
model6$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
#print(model6)
grid2 <-  expand.grid(
nrounds = c(100, 150, 200, 250),
eta = c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5),
lambda = c(0, 0.1, 0.01, 0.001, 1),
alpha = = c(0, 0.1, 0.01, 0.001, 1)
)
model7 <- train(status~., data = filtered_train, method = 'xgbLinear', tuneGrid = grid2, metric="ROC", trControl = control)
# top 5 results
model7$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
grid2 <-  expand.grid(
nrounds = c(100, 150, 200, 250),
eta = c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5),
lambda = c(0, 0.1, 0.01, 0.001, 1),
alpha = = c(0, 0.1, 0.01, 0.001, 1))
grid2 <-  expand.grid(
nrounds = c(100, 150, 200, 250),
eta = c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5),
lambda = c(0, 0.1, 0.01, 0.001, 1),
alpha = c(0, 0.1, 0.01, 0.001, 1))
grid2 <-  expand.grid(
nrounds = c(100, 150, 200, 250),
eta = c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5),
lambda = c(0, 0.1, 0.01, 0.001, 1),
alpha = c(0, 0.1, 0.01, 0.001, 1))
model7 <- train(status~., data = filtered_train, method = 'xgbLinear', tuneGrid = grid2, metric="ROC", trControl = control)
# top 5 results
model7$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
library(caret)
library(plyr)
library(xgboost)
# Loading and Preparing Datasets
train <- read.csv('complete_train.csv',sep = ',', header=TRUE)
test <- read.csv('complete_test.csv',sep = ',', header=TRUE)
# Converting 'status' to a factor
train$status <- factor(train$status)
levels(train$status) <- c("Failed", "Succeeded")
train %>% relocate(status, .after = last_col())
train <- train %>%
mutate(card_num = case_when(
card_num == 'none' ~ 0,
card_num == 'classic' ~ 1,
card_num == 'junior' ~ 2,
card_num == 'gold' ~ 3))
test <- test %>%
mutate(card_num = case_when(
card_num == 'none' ~ 0,
card_num == 'classic' ~ 1,
card_num == 'junior' ~ 2,
card_num == 'gold' ~ 3))
train <- train %>%
mutate(frequency_num = case_when(
frequency_num == 'monthly issuance' ~ 0,
frequency_num == 'weekly issuance' ~ 1,
frequency_num == 'issuance after transaction' ~ 2))
test <- test %>%
mutate(frequency_num = case_when(
frequency_num == 'monthly issuance' ~ 0,
frequency_num == 'weekly issuance' ~ 1,
frequency_num == 'issuance after transaction' ~ 2))
train <- train %>%
mutate(gender = case_when(
gender == 'F' ~ 0,
gender == 'M' ~ 2))
test <- test %>%
mutate(gender = case_when(
gender == 'F' ~ 0,
gender == 'M' ~ 2))
# Set a random seed
set.seed(100)
# Control
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
model <- train(status~., data = train, method = 'xgbDART', metric="ROC", trControl = control)
print(model)
model$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
grid <-  expand.grid(
nrounds = c(100, 150, 200, 250, 300, 350),
eta = c(0.05, 0.1, 0.2, 0.3, 0.4, 0.5),
max_depth = c(2, 4, 6, 8, 10),
gamma = 0,
colsample_bytree = 0.6,
min_child_weight = 1,
subsample = 0.5,
rate_drop = 0.5, skip_drop = 0.5
)
model2 <- train(status~., data = train, method = 'xgbDART', tuneGrid = grid, metric="ROC", trControl = control)
# top 5 results
model2$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
grid <-  expand.grid(
nrounds = c(100, 150, 200),
eta = c(0.05, 0.1, 0.2),
max_depth = c(2, 4, 6),
gamma = 0,
colsample_bytree = 0.6,
min_child_weight = 1,
subsample = 0.5,
rate_drop = 0.5, skip_drop = 0.5
)
model2 <- train(status~., data = train, method = 'xgbDART', tuneGrid = grid, metric="ROC", trControl = control)
# top 5 results
model2$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
library(Boruta)
boruta_output <- Boruta(status ~ ., data=na.omit(train), doTrace=0)
names(boruta_output)
# Get significant variables including tentatives
boruta_signif <- getSelectedAttributes(boruta_output, withTentative = TRUE)
print(boruta_signif)
features <- append(boruta_signif, "status")
filtered_train <- train[,features]
model3 <- train(status~., data = filtered_train, method = 'xgbDART', metric="ROC", trControl = control)
model3$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
model4 <- train(status~., data = filtered_train, method = 'xgbDART', tuneGrid = grid, metric="ROC", trControl = control)
# top 5 results
model4$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
#print(model4)
# Predicting
test$status <- predict(model3, newdata = test, type = "prob")
# Save Results
results_2 <- test[,c("loan_id","status")]
results_2$status_neg_prob <- results_2$status$Failed
export <- results_2[,c("loan_id", "status_neg_prob")]
names(export)[names(export) == 'loan_id' ] <- 'Id'
names(export)[names(export) == 'status_neg_prob' ] <- 'Predicted'
rm(results_2)
write.csv(export,"results/xgbDart_boruta.csv", row.names = FALSE)
rm(export)
test$status <- NULL
grid <-  expand.grid(
nrounds = c(100, 150, 200),
eta = c(0.05, 0.1, 0.2),
max_depth = c(2, 4, 6),
gamma = 0,
colsample_bytree = 0.6,
min_child_weight = 1,
subsample = 0.5,
rate_drop = 0.5, skip_drop = 0.5
)
model4 <- train(status~., data = filtered_train, method = 'xgbDART', tuneGrid = grid, metric="ROC", trControl = control)
# top 5 results
model4$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
control_fs <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
train %>% relocate(status, .after = last_col())
results_fs <- rfe(train[,1:39], train[,40], sizes=c(1:39), rfeControl=control_fs)
# summarize the results
print(results_fs)
# list the chosen features
predictors(results_fs)
# plot the results
plot(results_fs, type=c("g", "o"))
features <- append(predictors(results_fs), "status")
filtered_train_rfe <- train[,features]
clients <- read.csv('../ficheiros_competicao/client.csv',sep = ';', header=TRUE)
clients <- read.csv('./ficheiros_competicao/client.csv',sep = ';', header=TRUE)
2020-1938
library(caret)
library(mlbench)
library(xgboost)
# Loading and Preparing Datasets
train <- read.csv('./complete_train.csv',sep = ',', header=TRUE)
test <- read.csv('./complete_test.csv',sep = ',', header=TRUE)
# Converting 'status' to a factor
train$status <- factor(train$status)
levels(train$status) <- c("Failed", "Succeeded")
# Set a random seed
set.seed(100)
# Control
control <- trainControl(method="cv", number=5, classProbs=TRUE, summaryFunction=twoClassSummary)
library(Boruta)
boruta_output <- Boruta(status ~ ., data=na.omit(train), doTrace=0)
names(boruta_output)
# Get significant variables including tentatives
boruta_signif <- getSelectedAttributes(boruta_output, withTentative = TRUE)
print(boruta_signif)
features <- append(boruta_signif, "status")
filtered_train <- train[,features]
# pack the training control parameters
xgb_trcontrol_1 = trainControl(
method = "cv",
number = 5,
verboseIter = TRUE,
returnData = FALSE,
returnResamp = "all",
classProbs = TRUE,
summaryFunction = twoClassSummary,
allowParallel = TRUE
)
grid_test = expand.grid(
nrounds = c(150, 200, 300),
eta = c(0.1, 0.2),
max_depth = c(8, 10),
gamma = 1,
colsample_bytree = c(0.25, 0.5, 0.75, 1),
min_child_weight = 1,
subsample =  c(0.5, 0.75, 1)
)
model_test <- train(status~., data = filtered_train, method = 'xgbTree',
metric="ROC", trControl = xgb_trcontrol_1, tuneGrid = grid_test)
model_test$results %>%
top_n(5, wt = ROC) %>%
arrange(desc(ROC))
#Predict
test$status <- predict(model_test, newdata = test, type='prob')
test$status
results <- test[,c("loan_id","status")]
results$status_neg_prob <- results$status$Failed
export <- results[,c("loan_id", "status_neg_prob")]
names(export)[names(export) == 'loan_id' ] <- 'Id'
names(export)[names(export) == 'status_neg_prob' ] <- 'Predicted'
write.csv(export,"./results/xgb_grid_boruta.csv", row.names = FALSE)
